{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "43293aa1",
      "metadata": {
        "id": "43293aa1"
      },
      "source": [
        "# PES University, Bangalore\n",
        "Established under Karnataka Act No. 16 of 2013"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce2cfd11",
      "metadata": {
        "id": "ce2cfd11"
      },
      "source": [
        "## UE20CS312 - Data Analytics - Worksheet 4a\n",
        "Course instructor: Gowri Srinivasa, Professor Dept. of CSE, PES University  \n",
        "Designed by Harshith Mohan Kumar, Dept. of CSE - harshithmohankumar@pesu.pes.edu  \n",
        "  \n",
        "Renita Kurian - PES1UG20CS331"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e54bb19",
      "metadata": {
        "id": "6e54bb19"
      },
      "source": [
        "### Collaborative & Content based filtering\n",
        "The **Collaborative filtering method** for recommender systems is a method that is solely based on the past interactions that have been recorded between users and items, in order to produce new recommendations.\n",
        "\n",
        "The **Content-based** approach uses additional information about users and/or items. The Content-based approach requires a good amount of information about items’ features, rather than using the user’s interactions and feedback."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85df931b",
      "metadata": {
        "id": "85df931b"
      },
      "source": [
        "### Prerequisites\n",
        "- Revise the following concepts\n",
        "    - TF-IDF\n",
        "    - Content-based filtering\n",
        "    - Cosine Similarity\n",
        "- Install the following software\n",
        "    - pandas\n",
        "    - numpy\n",
        "    - sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91724e19",
      "metadata": {
        "id": "91724e19"
      },
      "source": [
        "### Task\n",
        "After the disastrous pitfall of [Game of Thrones season 8](https://en.wikipedia.org/wiki/Game_of_Thrones_(season_8)), George R. R. Martin set out to fix mindless mistakes caused by the producers David and Daniel.\n",
        "\n",
        "A few years down the line, we now are witnessing George R. R. Martin's latest work: [House of the Dragon](https://www.hotstar.com/in/tv/house-of-the-dragon/1260110208). This series is a story of the Targaryen civil war that took place about 200 years before events portrayed in Game of Thrones.\n",
        "\n",
        "In this notebook you will be exploring and analying tweets related to The House of Dragon TV series. First we shall tokenize the textual data using TF-IDF. Then we will proceed to find the top-k most similar tweets using cosine similarity between the transformed vectors.\n",
        "\n",
        "The dataset has been extracted using the [Twitter API](https://developer.twitter.com/en/docs/twitter-api) by utilizing a specific search query. The data has been extensively preprocessed and a small subset has been stored within the `twitter_HOTD_DA_WORKSHEET4A.csv`\n",
        "\n",
        "**Note:** This notebook may contain spoilers to the show."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b52f6a91",
      "metadata": {
        "id": "b52f6a91"
      },
      "source": [
        "### Data Dictionary\n",
        "**author_id**: A unique identifier assigned to the twitter user.\n",
        "\n",
        "**tweet_id**: A unique identifier assigned to the tweet.\n",
        "\n",
        "**text**: The text associated with the tweet.\n",
        "\n",
        "**retweet_count**: The number of retweets for this particular tweet.\n",
        "\n",
        "**reply_count**: The number of replies for this particular tweet.\n",
        "\n",
        "**like_count**: The number of likes for this particular tweet.\n",
        "\n",
        "**quote_count**: The number of quotes for this particular tweet.\n",
        "\n",
        "**tokens**: List of word tokens extracted from `text`.\n",
        "\n",
        "**hashtags**: List of hashtags extracted from `text`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4367b508",
      "metadata": {
        "id": "4367b508"
      },
      "source": [
        "### Points\n",
        "The problems in this worksheet are for a total of 10 points with each problem having a different weightage.\n",
        "- Problem 1: 4 points\n",
        "- Problem 2: 4 points\n",
        "- Problem 3: 2 points"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "350d259e",
      "metadata": {
        "id": "350d259e"
      },
      "source": [
        "### Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "d37bcaf7",
      "metadata": {
        "id": "d37bcaf7",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Import pandas\n",
        "import pandas as pd\n",
        "# Use pandas read_csv function to load csv as DataFrame\n",
        "df = pd.read_csv('./twitter_HOTD_DA_WORKSHEET4A.csv')\n",
        "#df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1d2e21c",
      "metadata": {
        "id": "d1d2e21c"
      },
      "source": [
        "### Problem 1 (4 points)\n",
        "\n",
        "Tokenize the string representations provided in the **tokens** column of the DataFrame using TF-IDF from sklearn. Then print out the TF-IDF of the first row of the DataFrame.\n",
        "\n",
        "Solution Steps:\n",
        "1. Initialize the `TfidfVectorizer()`\n",
        "2. Use the `.fit_transform()` method on the entire text\n",
        "3. `.transform()` the Text\n",
        "4. Print number of samples and features using `.shape`\n",
        "5. Print the TF-IDF of the first row\n",
        "\n",
        "For futher reference: https://www.analyticsvidhya.com/blog/2021/09/creating-a-movie-reviews-classifier-using-tf-idf-in-python/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "e9962516",
      "metadata": {
        "id": "e9962516"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import numpy as np \n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "30b80d7b",
      "metadata": {
        "id": "30b80d7b",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Convert string representation of a list into a list of strings\n",
        "import ast\n",
        "text = []\n",
        "for r in df['tokens']:\n",
        "    res = ast.literal_eval(r)\n",
        "    if(' '.join(res).lower() == ''):\n",
        "        print(r)\n",
        "    text.append(' '.join(res).lower())\n",
        "# Print the end result\n",
        "#text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "XJQrcKxecpjX",
      "metadata": {
        "id": "XJQrcKxecpjX"
      },
      "outputs": [],
      "source": [
        "v=TfidfVectorizer()\n",
        "wc_vec=v.fit_transform(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "-cJPR_FKcsUr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cJPR_FKcsUr",
        "outputId": "fb7790ed-12cd-4c4f-f6ae-e3aed163f322"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(8061, 10950)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wc_vec.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "Mohu2G3fcuKC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mohu2G3fcuKC",
        "outputId": "d5fcf3cb-ed38-4e27-9696-644d9b396b76"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TfidfTransformer()"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_transformer = TfidfTransformer(smooth_idf=True,use_idf=True) \n",
        "tfidf_transformer.fit(wc_vec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "XBg-AOKHcwWS",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBg-AOKHcwWS",
        "outputId": "5acef398-f33a-4d22-a145-590488aeeeb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "perform 9.301769763117166\n",
            "duty 7.7976923663408915\n",
            "mother 6.233716827983549\n",
            "betrothed 9.301769763117166\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "# print idf values \n",
        "df_idf = pd.DataFrame(tfidf_transformer.idf_, index=v.get_feature_names(),columns=[\"tokens\"]) \n",
        "# sort ascending \n",
        "final = df_idf.sort_values(by=['tokens'])\n",
        "final.loc['dragon']['tokens']\n",
        "row1_list = text[0].split()\n",
        "for i in row1_list:\n",
        "  print(i, final.loc[i]['tokens'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a148335d",
      "metadata": {
        "id": "a148335d"
      },
      "source": [
        "### Problem 2 (4 points)\n",
        "\n",
        "Find the top-5 most similar tweets to the tweet with index `7558` using cosine similarity between the TF-IDF vectors.\n",
        "\n",
        "Solution Steps:\n",
        "1. Import `cosine_similarity` from sklearn.metrics.pairwise\n",
        "2. Compute `cosine_similarity` using text_tf with index `7558` and all other rows\n",
        "3. Use `argsort` to sort the cosine_similarity results\n",
        "4. Print indices of top-5 most similar results from sorted array (hint: argsort sorts in ascending order)\n",
        "5. Display text of top-5 most similar results using `df.iloc[index]`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "828f9966",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "828f9966",
        "outputId": "43c31db5-7606-4c06-962c-ac8e6f328f24",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "viserys wanna build lego set mind business let man live peace\n",
            "rt viserys just wanna build his lego set and mind his business . let that man live in peace #houseofthedragon\n"
          ]
        }
      ],
      "source": [
        "# Print out the tokens from index `7654`\n",
        "print(text[7558])\n",
        "# Print out the text from index `7654`\n",
        "print(df.iloc[7558][2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "OPCktCbedHyC",
      "metadata": {
        "id": "OPCktCbedHyC"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "LmdI1R7EdK52",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmdI1R7EdK52",
        "outputId": "f07354ed-ef11-4324-f103-4ab6a6deef5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 1. 0. 0.]\n",
            " [0. 0. 0. ... 0. 1. 0.]\n",
            " [0. 0. 0. ... 0. 0. 1.]]\n"
          ]
        }
      ],
      "source": [
        "tfidf = TfidfVectorizer().fit_transform(text)\n",
        "cos_similarity = cosine_similarity(tfidf, tfidf)\n",
        "print(cos_similarity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "6vYew315dSBO",
      "metadata": {
        "id": "6vYew315dSBO"
      },
      "outputs": [],
      "source": [
        "def get_recommendations(title, cos_s):\n",
        "    idx = 7558\n",
        "    scores = list(enumerate(cos_s[idx]))\n",
        "    scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
        "    scores = scores[1:6]\n",
        "    indices = [i[0] for i in scores]\n",
        "    return df.iloc[indices]['text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "1Aq7-QnBdTmg",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Aq7-QnBdTmg",
        "outputId": "ae217805-e5e0-4ff4-cf9f-04dcd45213a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7595    viserys just wanna build his lego set and mind...\n",
            "3656    rt my man's literally just trying to build a l...\n",
            "6548    rt daemon and rhaenyra are never letting this ...\n",
            "7705    mom said it's my turn on the valyrian lego set...\n",
            "3534    rt don't play with them. they're here for busi...\n",
            "Name: text, dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(get_recommendations(text[7558], cos_similarity))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc084c7a",
      "metadata": {
        "id": "dc084c7a"
      },
      "source": [
        "### Problem 3 (2 point)\n",
        "\n",
        "A great disadvantage in using TF-IDF is that it can not capture semantics. If you had classify tweets into positive/negative, what technique would you use to map words to vectors? In short words, provide the sequence of solution steps to solve this task. Note: Assume sentiment labels have been provided. \n",
        "\n",
        "(Hint: take a look at how I've provided solution steps in previous problems)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "reLZAMIwh2H1",
      "metadata": {
        "id": "reLZAMIwh2H1"
      },
      "source": [
        "Solution Steps:\n",
        "  1. Remove stop words  \n",
        "  2. Lemmatize\n",
        "  3. Word Embedding -> map words to vector of real numbers. Continous Bag of Words Model can be used to predict word given context."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "350d259e"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 64-bit (microsoft store)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "ebde997db08c90800778fd1401ca73cb10440afad86db8640d60718307ced67c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
